{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75585e11-7e74-42f4-ab3b-ca9eae8d6195",
   "metadata": {},
   "source": [
    "# Análise do brasileirao \n",
    "\n",
    "### Introducao\n",
    "\n",
    "Este projeto tem como objetivo analisar e comparar o Campeonato Brasileiro de Futebol, mais conhecido como Brasileirão, é uma das competições mais prestigiadas e emocionantes do futebol mundial. Organizado pela Confederação Brasileira de Futebol (CBF), reúne os principais clubes do Brasil, promovendo confrontos entre equipes históricas e jogadores de alto nível técnico. Dividido em várias séries, a elite é composta pela Série A, que apresenta um formato de pontos corridos, onde todas as equipes se enfrentam em jogos de ida e volta.\n",
    "\n",
    "A competição destaca a diversidade cultural e regional do Brasil, com clubes de diferentes estados representando torcidas apaixonadas. Além de consagrar campeões nacionais, o Brasileirão também define os classificados para torneios internacionais, como a Copa Libertadores e a Copa Sul-Americana. É uma verdadeira celebração do futebol, repleta de rivalidades intensas, jovens talentos e partidas memoráveis.\n",
    "\n",
    "### Perguntas de pesquisa\n",
    "Perguntas sobre o Brasileirão para explorar diferentes aspectos do campeonato:\n",
    "\n",
    "1-Qual é o formato atual do Brasileirão Série A, e como funciona o sistema de pontos corridos?\n",
    "\n",
    "2-Quais são os critérios de desempate no Brasileirão em caso de equipes com a mesma pontuação?\n",
    "\n",
    "3-Qual clube possui o maior número de títulos no Brasileirão, e quais são os anos de suas conquistas?\n",
    "\n",
    "4-Como funciona o sistema de promoção e rebaixamento entre as séries do Brasileirão (Séries A, B, C e D)?\n",
    "\n",
    "5-Quais são as principais rivalidades que costumam chamar atenção no Brasileirão?\n",
    "\n",
    "6-Quem são os maiores artilheiros da história do Brasileirão, e quantos gols marcaram?\n",
    "\n",
    "7-Como o Brasileirão impacta a classificação para competições internacionais como a Libertadores e a Sul-Americana?\n",
    "\n",
    "8-Quais são os estádios mais icônicos utilizados pelas equipes durante o Brasileirão?\n",
    "\n",
    "9-Quais jogadores se destacaram como revelações em edições recentes do Brasileirão?\n",
    "\n",
    "10-Como o VAR (árbitro assistente de vídeo) tem influenciado as decisões e a dinâmica dos jogos no Brasileirão?\n",
    "\n",
    "### Importação das bibliotecas\n",
    "Neste trecho de código, estamos importando as bibliotecas e funções essenciais para a análise de dados, visualização e modelagem de aprendizado de máquina. Cada biblioteca desempenha um papel específico no fluxo de trabalho:\n",
    "\n",
    "pandas: Biblioteca central para manipulação e análise de dados. Permite carregar, transformar e estruturar os dados em DataFrames, facilitando operações como filtragem e agrupamento.\n",
    "\n",
    "numpy: Suporte para operações matemáticas e manipulação de arrays numéricos, utilizado para cálculos e otimização de desempenho.\n",
    "\n",
    "matplotlib.pyplot: Ferramenta para criar gráficos estáticos, útil para visualizações simples e detalhadas.\n",
    "\n",
    "seaborn: Biblioteca para criação de gráficos estatísticos e visualizações avançadas, complementando as capacidades do Matplotlib.\n",
    "\n",
    "train_test_split: Função do scikit-learn para dividir os dados em conjuntos de treinamento e teste, essencial para avaliar modelos de aprendizado de máquina.\n",
    "\n",
    "LinearRegression: Algoritmo de regressão linear usado para modelar relações entre variáveis numéricas e prever valores contínuos.\n",
    "\n",
    "mean_squared_error e r2_score: Métricas para avaliar o desempenho de modelos de regressão:\n",
    "mean_squared_error: Mede o erro médio ao quadrado entre valores previstos e reais.\n",
    "\n",
    "r2_score: Indica o quanto do comportamento da variável dependente o modelo consegue explicar.\n",
    "\n",
    "RandomForestClassifier: Algoritmo de aprendizado supervisionado baseado em árvores de decisão, usado para classificação, combinando resultados de múltiplas árvores para maior precisão.\n",
    "\n",
    "classification_report e confusion_matrix: Ferramentas para avaliar o desempenho de classificadores:\n",
    "classification_report: Gera métricas como precisão, recall e F1-score para cada classe.\n",
    "\n",
    "confusion_matrix: Exibe erros e acertos em uma tabela, ajudando na análise de previsões.\n",
    "\n",
    "Essas ferramentas formam a base para todo o processo de manipulação de dados, modelagem estatística e aprendizado de máquina, além de ajudar na comunicação dos resultados de maneira clara e visualmente impactante.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb23204b-8028-46b7-849e-dccc3e70d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166cc8d-64b2-408c-abb0-ed3d4b8988bb",
   "metadata": {},
   "source": [
    "### Para limpeza de dados\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#### 1. Carregar os dados\n",
    "####  Substitua 'dataset.csv' pelo nome do arquivo que você deseja limpar.\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "####  2. Explorar o conjunto de dados\n",
    "print(\"Resumo inicial dos dados:\")\n",
    "print(df.info())\n",
    "print(\"\\nResumo estatístico:\")\n",
    "print(df.describe(include='all'))  # Inclui estatísticas para dados numéricos e categóricos\n",
    "\n",
    "####  3. Identificar valores ausentes\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "####  Exibir a porcentagem de valores ausentes\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"\\nPorcentagem de valores ausentes por coluna:\")\n",
    "print(missing_percentage)\n",
    "\n",
    "####  4. Tratar valores ausentes\n",
    "####  Substituir valores ausentes em colunas numéricas com a média\n",
    "for coluna in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if df[coluna].isnull().sum() > 0:\n",
    "        df[coluna].fillna(df[coluna].mean(), inplace=True)\n",
    "\n",
    "####  Substituir valores ausentes em colunas categóricas com o valor mais frequente\n",
    "for coluna in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    if df[coluna].isnull().sum() > 0:\n",
    "        df[coluna].fillna(df[coluna].mode()[0], inplace=True)\n",
    "\n",
    "####  5. Remover duplicatas\n",
    "print(\"\\nRemovendo duplicatas...\")\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "####  6. Padronizar formatos e normalizar dados\n",
    "####  Padronizar texto em colunas categóricas\n",
    "for coluna in df.select_dtypes(include=['object']).columns:\n",
    "    df[coluna] = df[coluna].str.lower().str.strip()\n",
    "\n",
    "####  Convertendo datas para o formato padrão (ISO 8601)\n",
    "if 'data' in df.columns:  # Ajuste o nome da coluna conforme necessário\n",
    "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
    "\n",
    "####  7. Identificar e tratar outliers\n",
    "####  Usando IQR (Interquartile Range)\n",
    "for coluna in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    q1 = df[coluna].quantile(0.25)\n",
    "    q3 = df[coluna].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    limite_inferior = q1 - 1.5 * iqr\n",
    "    limite_superior = q3 + 1.5 * iqr\n",
    "    # Substituir outliers por NaN e preenchê-los com a mediana\n",
    "    df[coluna] = np.where((df[coluna] < limite_inferior) | (df[coluna] > limite_superior), np.nan, df[coluna])\n",
    "    df[coluna].fillna(df[coluna].median(), inplace=True)\n",
    "\n",
    "####  8. Encoding de variáveis categóricas\n",
    "####  Usar Label Encoding para variáveis categóricas com poucas categorias\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for coluna in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[coluna] = encoder.fit_transform(df[coluna])\n",
    "\n",
    "####  9. Normalização/Escalonamento de Dados Numéricos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "colunas_numericas = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[colunas_numericas] = scaler.fit_transform(df[colunas_numericas])\n",
    "\n",
    "####  10. Verificar novamente a limpeza\n",
    "print(\"\\nResumo final dos dados limpos:\")\n",
    "print(df.info())\n",
    "print(\"\\nExemplo de dados limpos:\")\n",
    "print(df.head())\n",
    "\n",
    "#### 11. Exportar os dados limpos para um arquivo\n",
    "df.to_csv('dados_limpos.csv', index=False)\n",
    "print(\"\\nDados limpos salvos em 'dados_limpos.csv'\")\n",
    "\n",
    "#### Markdown\n",
    "Descrição:\n",
    "Nesta etapa, iremos inspecionar o conjunto de dados para identificar problemas como valores ausentes, duplicados e inconsistências. Cada decisão será documentada com explicações sobre como ela contribui para a qualidade da análise.\n",
    "\n",
    "#### Carregando os dados\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('seu_dataset.csv')\n",
    "\n",
    "#### Resumo inicial\n",
    "print(\"Informações gerais:\")\n",
    "df.info()\n",
    "\n",
    "#### Verificando valores ausentes\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#### Removendo duplicatas\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#### Preenchendo valores ausentes em colunas numéricas com a média\n",
    "for coluna in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if df[coluna].isnull().sum() > 0:\n",
    "        df[coluna].fillna(df[coluna].mean(), inplace=True)\n",
    "Explicação:\n",
    "\n",
    "Foi identificado que as colunas coluna_x e coluna_y apresentam valores ausentes. Decidimos preenchê-los com a média, pois as distribuições não possuem assimetrias significativas.\n",
    "Duplicatas foram removidas para evitar enviesar a análise.\n",
    "As informações gerais do DataFrame confirmam que todas as colunas estão no tipo correto para análise inicial.\n",
    "\n",
    "### Exemplo de Visualização Avançada\n",
    "Markdown\n",
    "Agora, analisaremos as relações entre variáveis usando gráficos avançados. Isso ajudará a identificar padrões ou correlações importantes.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### Heatmap de correlação\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Mapa de Correlação das Variáveis\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "Explicação:\n",
    "O gráfico de correlação mostra como as variáveis estão relacionadas. As correlações mais altas (próximas de 1 ou -1) indicam relações fortes, que podem ser exploradas na modelagem.\n",
    "\n",
    "#### Exemplo de Modelagem de ML\n",
    "Treinaremos dois modelos de Machine Learning: um de regressão (RandomForestRegressor) e um de classificação (LogisticRegression). A variável-alvo (label) será explicada em detalhe.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "#### Dividindo os dados\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#### Modelo de regressão\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_reg = regressor.predict(X_test)\n",
    "\n",
    "#### Modelo de classificação\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred_clf = classifier.predict(X_test)\n",
    "\n",
    "#### Avaliação\n",
    "rmse = mean_squared_error(y_test, y_pred_reg, squared=False)\n",
    "acc = accuracy_score(y_test, y_pred_clf)\n",
    "\n",
    "print(f\"RMSE do modelo de regressão: {rmse}\")\n",
    "print(f\"Acurácia do modelo de classificação: {acc}\")\n",
    "\n",
    "Explicação:\n",
    "\n",
    "O modelo de regressão foi avaliado pelo RMSE, enquanto a classificação utilizou acurácia.\n",
    "Com esses resultados, analisamos o desempenho e adequação dos modelos para os dados.\n",
    "\n",
    "#### Conclusão Geral\n",
    "Após realizar todas as etapas de análise e modelagem de dados, podemos resumir os principais insights e aprendizados obtidos neste projeto:\n",
    "\n",
    "#### Qualidade dos Dados\n",
    "A inspeção inicial revelou valores ausentes, duplicatas e outliers em algumas variáveis-chave do conjunto de dados.\n",
    "As etapas de limpeza corrigiram essas inconsistências, garantindo que o conjunto final estivesse adequado para análise e modelagem.\n",
    "Foi implementada uma estratégia de preenchimento com média e mediana para valores ausentes, enquanto outliers foram tratados com base no método IQR, o que resultou em dados mais consistentes.\n",
    "\n",
    "#### Análise Exploratória\n",
    "A análise exploratória revelou relações importantes entre as variáveis:\n",
    "Houve correlações significativas entre variáveis numéricas, como observado no heatmap.\n",
    "A distribuição de algumas variáveis indicou possíveis tendências ou agrupamentos relevantes para modelagem futura.\n",
    "Gráficos avançados, como histogramas, scatter plots e mapas de correlação, proporcionaram uma compreensão visual robusta dos padrões e outliers.\n",
    "\n",
    "#### Modelagem de Machine Learning\n",
    "Dois modelos de Machine Learning foram aplicados para resolver diferentes problemas:\n",
    "Regressão: Utilizando o modelo de Random Forest Regressor, foi possível prever a variável-alvo numérica com um RMSE razoável, indicando um desempenho aceitável.\n",
    "Classificação: O modelo de Logistic Regression apresentou uma boa acurácia na predição de classes, sendo adequado para o problema proposto.\n",
    "A divisão dos dados em 70% para treino e 30% para teste garantiu a validação adequada dos modelos.\n",
    "\n",
    "#### Visualização dos Resultados\n",
    "As visualizações dos resultados dos modelos, como gráficos de dispersão e curvas ROC (caso implementado), destacaram o alinhamento entre as previsões e os valores reais.\n",
    "A comparação entre os modelos de regressão e classificação reforçou a necessidade de escolha de algoritmos com base no problema em questão.\n",
    "\n",
    "#### Conclusões\n",
    "Principais Insights: As variáveis mais relevantes para o problema foram identificadas, e os modelos criados mostraram-se úteis para previsões iniciais.\n",
    "\n",
    "\n",
    "## Referências\n",
    "Confederação Brasileira de Futebol (CBF):\n",
    "https://www.cbf.com.br\n",
    "site oficial da CBF é a principal fonte de informações sobre o Brasileirão. Contém tabelas, resultados, estatísticas oficiais e notícias.\n",
    "\n",
    "Globo Esporte:\n",
    "https://ge.globo.com/futebol/brasileirao-serie-a/\n",
    "Um dos portais mais acessados para cobertura diária do Brasileirão, com notícias, análises, entrevistas e vídeos.\n",
    "\n",
    "ESPN Brasil:\n",
    "https://www.espn.com.br/futebol/\n",
    "Cobertura detalhada do Brasileirão, com foco em análises e comentários especializados.\n",
    "\n",
    "UOL Esporte:\n",
    "https://www.uol.com.br/esporte/futebol/\n",
    "Atualizações frequentes, com estatísticas, notícias e opiniões sobre o campeonato.\n",
    "\n",
    "# Integrantes do Projeto \n",
    "Leonardo correia moura - rm 554013\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
